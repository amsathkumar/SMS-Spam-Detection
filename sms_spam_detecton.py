# -*- coding: utf-8 -*-
"""SMS spam detecton.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1wuYE8fEBV_3JIXXJWjCfPSUCGa5DGnfL
"""

import pandas as pd
import numpy as np
from sklearn.model_selection import train_test_split
from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.naive_bayes import MultinomialNB
from sklearn.metrics import classification_report, confusion_matrix
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Dense, LSTM, Embedding, SpatialDropout1D
from tensorflow.keras.preprocessing.sequence import pad_sequences
from tensorflow.keras.preprocessing.text import Tokenizer

# Load the dataset (you can download it from UCI Machine Learning Repository)
url = "https://raw.githubusercontent.com/epfml/ML_Projects/master/SMS_Spam_Collection/SMSSpamCollection"
data = pd.read_csv(url, sep='\t', names=['label', 'message'])

# Encode labels: spam as 1 and ham as 0
data['label'] = data['label'].map({'spam': 1, 'ham': 0})

# Split the dataset into training and testing sets
X_train, X_test, y_train, y_test = train_test_split(data['message'], data['label'], test_size=0.2, random_state=42)

# Text Vectorization using TF-IDF
tfidf = TfidfVectorizer()
X_train_tfidf = tfidf.fit_transform(X_train).toarray()
X_test_tfidf = tfidf.transform(X_test).toarray()

# Naive Bayes Model
nb_model = MultinomialNB()
nb_model.fit(X_train_tfidf, y_train)
y_pred_nb = nb_model.predict(X_test_tfidf)

# Evaluation of Naive Bayes Model
print("Naive Bayes Model Evaluation:")
print(classification_report(y_test, y_pred_nb))
print(confusion_matrix(y_test, y_pred_nb))

# Prepare data for LSTM model
max_words = 5000
max_len = 50

tokenizer = Tokenizer(num_words=max_words)
tokenizer.fit_on_texts(X_train)
X_train_seq = tokenizer.texts_to_sequences(X_train)
X_test_seq = tokenizer.texts_to_sequences(X_test)

X_train_pad = pad_sequences(X_train_seq, maxlen=max_len)
X_test_pad = pad_sequences(X_test_seq, maxlen=max_len)

# Build LSTM Model
lstm_model = Sequential()
lstm_model.add(Embedding(max_words, 128, input_length=max_len))
lstm_model.add(SpatialDropout1D(0.2))
lstm_model.add(LSTM(100))
lstm_model.add(Dense(1, activation='sigmoid'))

lstm_model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])

# Train LSTM Model
lstm_model.fit(X_train_pad, y_train, epochs=5, batch_size=64)

# Evaluate LSTM Model
y_pred_lstm = (lstm_model.predict(X_test_pad) > 0.5).astype("int32")

print("LSTM Model Evaluation:")
print(classification_report(y_test, y_pred_lstm))
print(confusion_matrix(y_test, y_pred_lstm))

# Assuming you downloaded the dataset locally as 'SMSSpamCollection.txt'
data = pd.read_csv('path/to/your/SMSSpamCollection.txt', sep='\t', names=['label', 'message'])

import pandas as pd
import numpy as np
from sklearn.model_selection import train_test_split
from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.naive_bayes import MultinomialNB
from sklearn.metrics import classification_report, confusion_matrix
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Dense, LSTM, Embedding, SpatialDropout1D
from tensorflow.keras.preprocessing.sequence import pad_sequences
from tensorflow.keras.preprocessing.text import Tokenizer

# Load the dataset from a local file
data = pd.read_csv('path/to/your/SMSSpamCollection.txt', sep='\t', names=['label', 'message'])

# Encode labels: spam as 1 and ham as 0
data['label'] = data['label'].map({'spam': 1, 'ham': 0})

# Split the dataset into training and testing sets
X_train, X_test, y_train, y_test = train_test_split(data['message'], data['label'], test_size=0.2, random_state=42)

# Text Vectorization using TF-IDF
tfidf = TfidfVectorizer()
X_train_tfidf = tfidf.fit_transform(X_train).toarray()
X_test_tfidf = tfidf.transform(X_test).toarray()

# Naive Bayes Model
nb_model = MultinomialNB()
nb_model.fit(X_train_tfidf, y_train)
y_pred_nb = nb_model.predict(X_test_tfidf)

# Evaluation of Naive Bayes Model
print("Naive Bayes Model Evaluation:")
print(classification_report(y_test, y_pred_nb))
print(confusion_matrix(y_test, y_pred_nb))

# Prepare data for LSTM model
max_words = 5000
max_len = 50

tokenizer = Tokenizer(num_words=max_words)
tokenizer.fit_on_texts(X_train)
X_train_seq = tokenizer.texts_to_sequences(X_train)
X_test_seq = tokenizer.texts_to_sequences(X_test)

X_train_pad = pad_sequences(X_train_seq, maxlen=max_len)
X_test_pad = pad_sequences(X_test_seq, maxlen=max_len)

# Build LSTM Model
lstm_model = Sequential()
lstm_model.add(Embedding(max_words, 128, input_length=max_len))
lstm_model.add(SpatialDropout1D(0.2))
lstm_model.add(LSTM(100))
lstm_model.add(Dense(1, activation='sigmoid'))

lstm_model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])

# Train LSTM Model
lstm_model.fit(X_train_pad, y_train, epochs=5, batch_size=64)

# Evaluate LSTM Model
y_pred_lstm = (lstm_model.predict(X_test_pad) > 0.5).astype("int32")

print("LSTM Model Evaluation:")
print(classification_report(y_test, y_pred_lstm))
print(confusion_matrix(y_test, y_pred_lstm))

# SMS Spam Detection Using NLP

# Import necessary libraries
import pandas as pd
import numpy as np
import re
import string
from sklearn.model_selection import train_test_split
from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.linear_model import LogisticRegression
from sklearn.metrics import accuracy_score, classification_report, confusion_matrix

# Step 1: Load the dataset
from google.colab import files
uploaded = files.upload()

# Assuming the uploaded file is 'spam.csv'
df = pd.read_csv("spam.csv", encoding='latin-1')

# Rename and retain only relevant columns
df = df.rename(columns={"v1": "label", "v2": "message"})
df = df[["label", "message"]]

# Convert labels to binary (spam = 1, ham = 0)
df["label"] = df["label"].map({"ham": 0, "spam": 1})

# Step 2: Preprocess the text
def preprocess_text(text):
    text = text.lower()  # Convert to lowercase
    text = re.sub(r"\d+", "", text)  # Remove numbers
    text = re.sub(r"[{}]".format(re.escape(string.punctuation)), "", text)  # Remove punctuation
    text = re.sub(r"\s+", " ", text).strip()  # Remove extra spaces
    return text

df["cleaned_message"] = df["message"].apply(preprocess_text)

# Step 3: Split the dataset
X = df["cleaned_message"]
y = df["label"]
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

# Step 4: Feature extraction using TF-IDF
vectorizer = TfidfVectorizer(max_features=5000)
X_train_tfidf = vectorizer.fit_transform(X_train)
X_test_tfidf = vectorizer.transform(X_test)

# Step 5: Train the model
model = LogisticRegression()
model.fit(X_train_tfidf, y_train)

# Step 6: Evaluate the model
y_pred = model.predict(X_test_tfidf)
print("Accuracy:", accuracy_score(y_test, y_pred))
print("\nClassification Report:\n", classification_report(y_test, y_pred))
print("\nConfusion Matrix:\n", confusion_matrix(y_test, y_pred))

# Step 7: Test with custom messages
while True:
    custom_message = input("Enter a message to check (or type 'exit' to quit): ")
    if custom_message.lower() == 'exit':
        break
    custom_message_cleaned = preprocess_text(custom_message)
    custom_message_vectorized = vectorizer.transform([custom_message_cleaned])
    prediction = model.predict(custom_message_vectorized)[0]
    print("Spam" if prediction == 1 else "Ham")